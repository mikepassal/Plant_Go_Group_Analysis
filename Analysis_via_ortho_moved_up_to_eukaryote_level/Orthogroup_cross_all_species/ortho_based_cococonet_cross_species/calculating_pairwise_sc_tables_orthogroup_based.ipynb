{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "# appending a path\n",
    "sys.path.append('/data/passala/Python_Utils')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import CococoNet_reader\n",
    "import Name_resolver\n",
    "import os\n",
    "import itertools\n",
    "import warnings\n",
    "import pickle\n",
    "import tqdm\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coconet_species_one = pickle.load( open( \"/data/passala/Generated_Tables/Comparing_all_orthogorups_across_plants/Orthogroup_based_coconets/rice_jp_merged_cococonet_pickle.p\", \"rb\" ) )\n",
    "coconet_species_two = pickle.load( open( \"/data/passala/Generated_Tables/Comparing_all_orthogorups_across_plants/Orthogroup_based_coconets/soybean_merged_cococonet_pickle.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "common_name_1 = Name_resolver.species_name_resolver('rice_jp','common')\n",
    "common_name_2 = Name_resolver.species_name_resolver('soybean','common')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sc_table_formatted(coconet_species_one,coconet_species_two, common_name_1,common_name_2):\n",
    "\n",
    "\n",
    "    \n",
    "    trimmed_species_1_cococonet = coconet_species_one[coconet_species_one.columns.intersection(coconet_species_two.columns)]\n",
    "    trimmed_species_1_cococonet = trimmed_species_1_cococonet[trimmed_species_1_cococonet.index.isin(coconet_species_two.columns)]\n",
    "    double_species_1_trimmed_cococonet = trimmed_species_1_cococonet.replace(1,0)\n",
    "\n",
    "    trimmed_species_2_cococonet = coconet_species_two[coconet_species_two.columns.intersection(coconet_species_one.columns)]\n",
    "    trimmed_species_2_cococonet = trimmed_species_2_cococonet[trimmed_species_2_cococonet.index.isin(coconet_species_one.columns)]\n",
    "    double_species_2_trimmed_cococonet = trimmed_species_2_cococonet.replace(1,0)\n",
    "    cococonet_1_set_to_zero = double_species_1_trimmed_cococonet\n",
    "\n",
    "    cococonet_2_set_to_zero = double_species_2_trimmed_cococonet\n",
    "\n",
    "    top_10_cococonet_1genes = np.array(\n",
    "        [cococonet_1_set_to_zero[c].nlargest(10).index.values for c in cococonet_1_set_to_zero]\n",
    "    )  # using pair list above, cut down top 10 list to relevant genes, probably by adding list as a column in panda and then filtering panda to index of pair list\n",
    "    top_10_ccn_1_genes_dataframe = pd.DataFrame(\n",
    "        data=top_10_cococonet_1genes,\n",
    "        index=cococonet_1_set_to_zero.index,\n",
    "        columns=[\n",
    "            \"One\",\n",
    "            \"Two\",\n",
    "            \"Three\",\n",
    "            \"Four\",\n",
    "            \"Five\",\n",
    "            \"Six\",\n",
    "            \"Seven\",\n",
    "            \"Eight\",\n",
    "            \"Nine\",\n",
    "            \"Ten\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    tidy_top_10 = top_10_ccn_1_genes_dataframe.melt(ignore_index= False)\n",
    "\n",
    "    zipped_pairs = zip(tidy_top_10.index.to_list(),tidy_top_10['value'].to_list())\n",
    "    binary_masked_cococonet_1 = pd.DataFrame(data = 0, columns = cococonet_1_set_to_zero.columns, index = cococonet_1_set_to_zero.index)\n",
    "    #binary_masked_cococonet.loc[zip(tuple(tidy_top_10.index.to_list()),tuple(tidy_top_10['value'].to_list()))] = 1\n",
    "    #binary_masked_cococonet.sum(axis =0)\n",
    "    for row,column in zipped_pairs:\n",
    "        binary_masked_cococonet_1.at[row,column] = 1\n",
    "\n",
    "    ranked_columns_cococonet_2 = double_species_2_trimmed_cococonet.rank()\n",
    "\n",
    "    dot_product_cococonet_2 = binary_masked_cococonet_1.dot(ranked_columns_cococonet_2)\n",
    "    subtract_minimum_2 = dot_product_cococonet_2-65 # This is 11+10+9+8+7+6+5+4+3+2\n",
    "\n",
    "\n",
    "    function_conservations_scores_2 = subtract_minimum_2/(subtract_minimum_2.max().max() - subtract_minimum_2.min().min())\n",
    "    fc_scores_ranked_2=function_conservations_scores_2.rank()\n",
    "    sc_scores_2 = fc_scores_ranked_2/fc_scores_ranked_2.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    top_10_cococonet_2genes = np.array(\n",
    "        [cococonet_2_set_to_zero[c].nlargest(10).index.values for c in cococonet_2_set_to_zero]\n",
    "    )  # using pair list above, cut down top 10 list to relevant genes, probably by adding list as a column in panda and then filtering panda to index of pair list\n",
    "    top_10_ccn_2_genes_dataframe = pd.DataFrame(\n",
    "        data=top_10_cococonet_2genes,\n",
    "        index=cococonet_2_set_to_zero.index,\n",
    "        columns=[\n",
    "            \"One\",\n",
    "            \"Two\",\n",
    "            \"Three\",\n",
    "            \"Four\",\n",
    "            \"Five\",\n",
    "            \"Six\",\n",
    "            \"Seven\",\n",
    "            \"Eight\",\n",
    "            \"Nine\",\n",
    "            \"Ten\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    tidy_top_10 = top_10_ccn_2_genes_dataframe.melt(ignore_index= False)\n",
    "\n",
    "    zipped_pairs = zip(tidy_top_10.index.to_list(),tidy_top_10['value'].to_list())\n",
    "    binary_masked_cococonet_2 = pd.DataFrame(data = 0, columns = cococonet_2_set_to_zero.columns, index = cococonet_2_set_to_zero.index)\n",
    "    #binary_masked_cococonet.loc[zip(tuple(tidy_top_10.index.to_list()),tuple(tidy_top_10['value'].to_list()))] = 1\n",
    "    #binary_masked_cococonet.sum(axis =0)\n",
    "    for row,column in zipped_pairs:\n",
    "        binary_masked_cococonet_2.at[row,column] = 1\n",
    "\n",
    "    ranked_columns_cococonet_1 = double_species_1_trimmed_cococonet.rank()\n",
    "\n",
    "    dot_product_cococonet_1 = binary_masked_cococonet_2.dot(ranked_columns_cococonet_1)\n",
    "    subtract_minimum_1 = dot_product_cococonet_1-65 # This is 11+10+9+8+7+6+5+4+3+2\n",
    "\n",
    "\n",
    "    function_conservations_scores_1 = subtract_minimum_1/(subtract_minimum_1.max().max() - subtract_minimum_1.min().min())\n",
    "    fc_scores_ranked_1=function_conservations_scores_1.rank()\n",
    "    sc_scores_1 = fc_scores_ranked_1/fc_scores_ranked_1.shape[0]\n",
    "\n",
    "    transposed_1 = sc_scores_1.T\n",
    "\n",
    "    averaged_results = (sc_scores_2+transposed_1)/2\n",
    "    \n",
    "\n",
    "    ##process average Rsults to look like table \n",
    "    output = pd.DataFrame( columns = [f'{common_name_1} and {common_name_2}'], data = averaged_results.index )\n",
    "    output['Species 1 Score'] = 'compatability col'\n",
    "    output['Species 2 Score'] = 'compatability col'\n",
    "    output['Total Score'] = np.diag(averaged_results)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimmed_species_1_cococonet = coconet_species_one[coconet_species_one.columns.intersection(coconet_species_two.columns)]\n",
    "# trimmed_species_1_cococonet = trimmed_species_1_cococonet[trimmed_species_1_cococonet.index.isin(coconet_species_two.columns)]\n",
    "# double_species_1_trimmed_cococonet = trimmed_species_1_cococonet.replace(1,0)\n",
    "\n",
    "# trimmed_species_2_cococonet = coconet_species_two[coconet_species_two.columns.intersection(coconet_species_one.columns)]\n",
    "# trimmed_species_2_cococonet = trimmed_species_2_cococonet[trimmed_species_2_cococonet.index.isin(coconet_species_one.columns)]\n",
    "# double_species_2_trimmed_cococonet = trimmed_species_2_cococonet.replace(1,0)\n",
    "# cococonet_1_set_to_zero = double_species_1_trimmed_cococonet\n",
    "\n",
    "# cococonet_2_set_to_zero = double_species_2_trimmed_cococonet\n",
    "\n",
    "# top_10_cococonet_1genes = np.array(\n",
    "#     [cococonet_1_set_to_zero[c].nlargest(10).index.values for c in cococonet_1_set_to_zero]\n",
    "# )  # using pair list above, cut down top 10 list to relevant genes, probably by adding list as a column in panda and then filtering panda to index of pair list\n",
    "# top_10_ccn_1_genes_dataframe = pd.DataFrame(\n",
    "#     data=top_10_cococonet_1genes,\n",
    "#     index=cococonet_1_set_to_zero.index,\n",
    "#     columns=[\n",
    "#         \"One\",\n",
    "#         \"Two\",\n",
    "#         \"Three\",\n",
    "#         \"Four\",\n",
    "#         \"Five\",\n",
    "#         \"Six\",\n",
    "#         \"Seven\",\n",
    "#         \"Eight\",\n",
    "#         \"Nine\",\n",
    "#         \"Ten\",\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# tidy_top_10 = top_10_ccn_1_genes_dataframe.melt(ignore_index= False)\n",
    "\n",
    "# zipped_pairs = zip(tidy_top_10.index.to_list(),tidy_top_10['value'].to_list())\n",
    "# binary_masked_cococonet_1 = pd.DataFrame(data = 0, columns = cococonet_1_set_to_zero.columns, index = cococonet_1_set_to_zero.index)\n",
    "# #binary_masked_cococonet.loc[zip(tuple(tidy_top_10.index.to_list()),tuple(tidy_top_10['value'].to_list()))] = 1\n",
    "# #binary_masked_cococonet.sum(axis =0)\n",
    "# for row,column in zipped_pairs:\n",
    "#     binary_masked_cococonet_1.at[row,column] = 1\n",
    "\n",
    "# ranked_columns_cococonet_2 = double_species_2_trimmed_cococonet.rank()\n",
    "\n",
    "# dot_product_cococonet_2 = binary_masked_cococonet_1.dot(ranked_columns_cococonet_2)\n",
    "# subtract_minimum_2 = dot_product_cococonet_2-65 # This is 11+10+9+8+7+6+5+4+3+2\n",
    "\n",
    "\n",
    "# function_conservations_scores_2 = subtract_minimum_2/(subtract_minimum_2.max().max() - subtract_minimum_2.min().min())\n",
    "# fc_scores_ranked_2=function_conservations_scores_2.rank()\n",
    "# sc_scores_2 = fc_scores_ranked_2/fc_scores_ranked_2.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# top_10_cococonet_2genes = np.array(\n",
    "#     [cococonet_2_set_to_zero[c].nlargest(10).index.values for c in cococonet_2_set_to_zero]\n",
    "# )  # using pair list above, cut down top 10 list to relevant genes, probably by adding list as a column in panda and then filtering panda to index of pair list\n",
    "# top_10_ccn_2_genes_dataframe = pd.DataFrame(\n",
    "#     data=top_10_cococonet_2genes,\n",
    "#     index=cococonet_2_set_to_zero.index,\n",
    "#     columns=[\n",
    "#         \"One\",\n",
    "#         \"Two\",\n",
    "#         \"Three\",\n",
    "#         \"Four\",\n",
    "#         \"Five\",\n",
    "#         \"Six\",\n",
    "#         \"Seven\",\n",
    "#         \"Eight\",\n",
    "#         \"Nine\",\n",
    "#         \"Ten\",\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# tidy_top_10 = top_10_ccn_2_genes_dataframe.melt(ignore_index= False)\n",
    "\n",
    "# zipped_pairs = zip(tidy_top_10.index.to_list(),tidy_top_10['value'].to_list())\n",
    "# binary_masked_cococonet_2 = pd.DataFrame(data = 0, columns = cococonet_2_set_to_zero.columns, index = cococonet_2_set_to_zero.index)\n",
    "# #binary_masked_cococonet.loc[zip(tuple(tidy_top_10.index.to_list()),tuple(tidy_top_10['value'].to_list()))] = 1\n",
    "# #binary_masked_cococonet.sum(axis =0)\n",
    "# for row,column in zipped_pairs:\n",
    "#     binary_masked_cococonet_2.at[row,column] = 1\n",
    "\n",
    "# ranked_columns_cococonet_1 = double_species_1_trimmed_cococonet.rank()\n",
    "\n",
    "# dot_product_cococonet_1 = binary_masked_cococonet_2.dot(ranked_columns_cococonet_1)\n",
    "# subtract_minimum_1 = dot_product_cococonet_1-65 # This is 11+10+9+8+7+6+5+4+3+2\n",
    "\n",
    "\n",
    "# function_conservations_scores_1 = subtract_minimum_1/(subtract_minimum_1.max().max() - subtract_minimum_1.min().min())\n",
    "# fc_scores_ranked_1=function_conservations_scores_1.rank()\n",
    "# sc_scores_1 = fc_scores_ranked_1/fc_scores_ranked_1.shape[0]\n",
    "\n",
    "# transposed_1 = sc_scores_1.T\n",
    "\n",
    "# averaged_results = (sc_scores_2+transposed_1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# common_name_1 = Name_resolver.species_name_resolver('rice_jp','common')\n",
    "# common_name_2 = Name_resolver.species_name_resolver('apple','common')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## Read In Cococonets \n",
    "# coconet_species_one = coconet_1\n",
    "# coconet_species_two = coconet_2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #Identify Pairs for evaluation\n",
    "\n",
    "# pairs_to_keep = list(set(coconet_species_one.index.to_list()) & set(coconet_species_two.index.to_list()))\n",
    "\n",
    "# all_pairs_to_evaluate_for_functional_conservation = pd.DataFrame(columns = [f'{common_name_1} and {common_name_2}'],data= pairs_to_keep)\n",
    "\n",
    "\n",
    "# all_pairs_to_evaluate_for_functional_conservation['Species 1 Score'] = np.nan\n",
    "# all_pairs_to_evaluate_for_functional_conservation['Species 2 Score'] = np.nan\n",
    "\n",
    "\n",
    "# ## Trim cococonets to match\n",
    "\n",
    "\n",
    "# trimmed_species_1_cococonet = coconet_species_one[coconet_species_one.columns.intersection(pairs_to_keep)]\n",
    "# trimmed_species_1_cococonet = trimmed_species_1_cococonet[trimmed_species_1_cococonet.index.isin(pairs_to_keep)]\n",
    "# double_species_1_trimmed_cococonet = trimmed_species_1_cococonet.replace(1,0)\n",
    "\n",
    "# trimmed_species_2_cococonet = coconet_species_two[coconet_species_two.columns.intersection(pairs_to_keep)]\n",
    "# trimmed_species_2_cococonet = trimmed_species_2_cococonet[trimmed_species_2_cococonet.index.isin(pairs_to_keep)]\n",
    "# double_species_2_trimmed_cococonet = trimmed_species_2_cococonet.replace(1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Rank\n",
    "# species_1_cococonet_ranked = trimmed_species_1_cococonet.rank()\n",
    "# species_2_cococonet_ranked = trimmed_species_2_cococonet.rank()\n",
    "\n",
    "# #Do top 10 Genes\n",
    "# top_10_species_1_genes = np.array(\n",
    "#     [double_species_1_trimmed_cococonet.T[c].nlargest(10).index.values for c in double_species_1_trimmed_cococonet.T]\n",
    "# )  # using pair list above, cut down top 10 list to relevant genes, probably by adding list as a column in panda and then filtering panda to index of pair list\n",
    "# top_10_species_1_genes_dataframe = pd.DataFrame(\n",
    "#     data=top_10_species_1_genes,\n",
    "#     index=double_species_1_trimmed_cococonet.index,\n",
    "#     columns=[\n",
    "#         \"One\",\n",
    "#         \"Two\",\n",
    "#         \"Three\",\n",
    "#         \"Four\",\n",
    "#         \"Five\",\n",
    "#         \"Six\",\n",
    "#         \"Seven\",\n",
    "#         \"Eight\",\n",
    "#         \"Nine\",\n",
    "#         \"Ten\",\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# #Convert \n",
    "# top_10_species_1_genes_as_species_2 = top_10_species_1_genes_dataframe\n",
    "\n",
    "# # Get genes for checking \n",
    "# have_species_1_pairs = all_pairs_to_evaluate_for_functional_conservation.loc[all_pairs_to_evaluate_for_functional_conservation[f'{common_name_1} and {common_name_2}'].isin(top_10_species_1_genes_as_species_2.index)]\n",
    "# trimmed_all_gene_pairs_for_fc = have_species_1_pairs.loc[have_species_1_pairs[f'{common_name_1} and {common_name_2}'].isin(trimmed_species_2_cococonet.index)]\n",
    "# trimmed_all_gene_pairs_for_fc = trimmed_all_gene_pairs_for_fc.reset_index(drop = True)\n",
    "\n",
    "# # Get values in species 2 \n",
    "# for two_genes in trimmed_all_gene_pairs_for_fc.iterrows():\n",
    "#     current_species_1_gene = two_genes[1][f'{common_name_1} and {common_name_2}']\n",
    "#     current_species_2_gene = two_genes[1][f'{common_name_1} and {common_name_2}']\n",
    "#     finger_print_genes = top_10_species_1_genes_as_species_2.loc[current_species_1_gene].to_list()\n",
    "#     gene_ranks_in_species_2 = species_2_cococonet_ranked.loc[species_2_cococonet_ranked.index.isin(finger_print_genes), current_species_2_gene]\n",
    "#     avg_rank_in_species_2 = gene_ranks_in_species_2.mean()\n",
    "#     index_from_pairs = two_genes[0]\n",
    "#     trimmed_all_gene_pairs_for_fc.at[index_from_pairs, 'Species 1 Score'] = avg_rank_in_species_2\n",
    "\n",
    "# #Repeat for Species 2 \n",
    "\n",
    "# top_10_species_2_genes = np.array(\n",
    "#     [double_species_2_trimmed_cococonet.T[c].nlargest(10).index.values for c in double_species_2_trimmed_cococonet.T]\n",
    "# )  # using pair list above, cut down top 10 list to relevant genes, probably by adding list as a column in panda and then filtering panda to index of pair list\n",
    "# top_10_species_2_genes_dataframe = pd.DataFrame(\n",
    "#     data=top_10_species_2_genes,\n",
    "#     index=double_species_2_trimmed_cococonet.index,\n",
    "#     columns=[\n",
    "#         \"One\",\n",
    "#         \"Two\",\n",
    "#         \"Three\",\n",
    "#         \"Four\",\n",
    "#         \"Five\",\n",
    "#         \"Six\",\n",
    "#         \"Seven\",\n",
    "#         \"Eight\",\n",
    "#         \"Nine\",\n",
    "#         \"Ten\",\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "\n",
    "# #convert \n",
    "# top_10_species_2_genes_as_species_1 = top_10_species_2_genes_dataframe\n",
    "\n",
    "\n",
    "# # Get values in species 1 \n",
    "# for two_genes in trimmed_all_gene_pairs_for_fc.iterrows():\n",
    "#     current_species_1_gene = two_genes[1][f'{common_name_1} and {common_name_2}']\n",
    "#     current_species_2_gene = two_genes[1][f'{common_name_1} and {common_name_2}']\n",
    "#     finger_print_genes = top_10_species_2_genes_as_species_1.loc[current_species_2_gene].to_list()\n",
    "#     gene_ranks_in_species_1 = species_1_cococonet_ranked.loc[species_1_cococonet_ranked.index.isin(finger_print_genes), current_species_1_gene]\n",
    "#     avg_rank_in_species_1 = gene_ranks_in_species_1.mean()\n",
    "#     index_from_pairs = two_genes[0]\n",
    "#     trimmed_all_gene_pairs_for_fc.loc[index_from_pairs, 'Species 2 Score'] = avg_rank_in_species_1\n",
    "\n",
    "# #Caluclate Divisors \n",
    "# Number_of_species_1_genes = len(top_10_species_1_genes_as_species_2)\n",
    "# Number_of_species_2_genes = len(top_10_species_2_genes_as_species_1)\n",
    "\n",
    "\n",
    "# species_1_score_divisor = Number_of_species_2_genes - 4.5\n",
    "# species_2_score_divisor = Number_of_species_1_genes-4.5\n",
    "\n",
    "# #Divide and Average \n",
    "# trimmed_all_gene_pairs_for_fc['Species 1 Score'] = trimmed_all_gene_pairs_for_fc['Species 1 Score']/species_1_score_divisor\n",
    "# trimmed_all_gene_pairs_for_fc['Species 2 Score'] = trimmed_all_gene_pairs_for_fc['Species 2 Score']/species_2_score_divisor\n",
    "# trimmed_all_gene_pairs_for_fc['Total Score'] = trimmed_all_gene_pairs_for_fc[['Species 1 Score','Species 2 Score']].mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_Score_list_for_thresholding(coconet_1, coconet_2, Species_1 = 'rice',Species_2 = 'maize', ):\n",
    "\n",
    "    import pandas as pd\n",
    "    import itertools\n",
    "\n",
    "    common_name_1 = Name_resolver.species_name_resolver(Species_1,'common')\n",
    "    common_name_2 = Name_resolver.species_name_resolver(Species_2,'common')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## Read In Cococonets \n",
    "    coconet_species_one = coconet_1\n",
    "    coconet_species_two = coconet_2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Identify Pairs for evaluation\n",
    "\n",
    "    pairs_to_keep = list(set(coconet_species_one.index.to_list()) & set(coconet_species_two.index.to_list()))\n",
    "\n",
    "    all_pairs_to_evaluate_for_functional_conservation = pd.DataFrame(columns = [f'{common_name_1} and {common_name_2}'],data= pairs_to_keep)\n",
    "\n",
    "\n",
    "    all_pairs_to_evaluate_for_functional_conservation['Species 1 Score'] = np.nan\n",
    "    all_pairs_to_evaluate_for_functional_conservation['Species 2 Score'] = np.nan\n",
    "\n",
    "\n",
    "    ## Trim cococonets to match\n",
    "\n",
    "\n",
    "    trimmed_species_1_cococonet = coconet_species_one[coconet_species_one.columns.intersection(pairs_to_keep)]\n",
    "    trimmed_species_1_cococonet = trimmed_species_1_cococonet[trimmed_species_1_cococonet.index.isin(pairs_to_keep)]\n",
    "    double_species_1_trimmed_cococonet = trimmed_species_1_cococonet.replace(1,0)\n",
    "\n",
    "    trimmed_species_2_cococonet = coconet_species_two[coconet_species_two.columns.intersection(pairs_to_keep)]\n",
    "    trimmed_species_2_cococonet = trimmed_species_2_cococonet[trimmed_species_2_cococonet.index.isin(pairs_to_keep)]\n",
    "    double_species_2_trimmed_cococonet = trimmed_species_2_cococonet.replace(1,0)\n",
    "\n",
    "\n",
    "\n",
    "    ## Rank\n",
    "    species_1_cococonet_ranked = trimmed_species_1_cococonet.rank()\n",
    "    species_2_cococonet_ranked = trimmed_species_2_cococonet.rank()\n",
    "\n",
    "    #Do top 10 Genes\n",
    "    top_10_species_1_genes = np.array(\n",
    "        [double_species_1_trimmed_cococonet.T[c].nlargest(10).index.values for c in double_species_1_trimmed_cococonet.T]\n",
    "    )  # using pair list above, cut down top 10 list to relevant genes, probably by adding list as a column in panda and then filtering panda to index of pair list\n",
    "    top_10_species_1_genes_dataframe = pd.DataFrame(\n",
    "        data=top_10_species_1_genes,\n",
    "        index=double_species_1_trimmed_cococonet.index,\n",
    "        columns=[\n",
    "            \"One\",\n",
    "            \"Two\",\n",
    "            \"Three\",\n",
    "            \"Four\",\n",
    "            \"Five\",\n",
    "            \"Six\",\n",
    "            \"Seven\",\n",
    "            \"Eight\",\n",
    "            \"Nine\",\n",
    "            \"Ten\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    #Convert \n",
    "    top_10_species_1_genes_as_species_2 = top_10_species_1_genes_dataframe\n",
    "\n",
    "    # Get genes for checking \n",
    "    have_species_1_pairs = all_pairs_to_evaluate_for_functional_conservation.loc[all_pairs_to_evaluate_for_functional_conservation[f'{common_name_1} and {common_name_2}'].isin(top_10_species_1_genes_as_species_2.index)]\n",
    "    trimmed_all_gene_pairs_for_fc = have_species_1_pairs.loc[have_species_1_pairs[f'{common_name_1} and {common_name_2}'].isin(trimmed_species_2_cococonet.index)]\n",
    "    trimmed_all_gene_pairs_for_fc = trimmed_all_gene_pairs_for_fc.reset_index(drop = True)\n",
    "\n",
    "    # Get values in species 2 \n",
    "    for two_genes in trimmed_all_gene_pairs_for_fc.iterrows():\n",
    "        current_species_1_gene = two_genes[1][f'{common_name_1} and {common_name_2}']\n",
    "        current_species_2_gene = two_genes[1][f'{common_name_1} and {common_name_2}']\n",
    "        finger_print_genes = top_10_species_1_genes_as_species_2.loc[current_species_1_gene].to_list()\n",
    "        gene_ranks_in_species_2 = species_2_cococonet_ranked.loc[species_2_cococonet_ranked.index.isin(finger_print_genes), current_species_2_gene]\n",
    "        avg_rank_in_species_2 = gene_ranks_in_species_2.mean()\n",
    "        index_from_pairs = two_genes[0]\n",
    "        trimmed_all_gene_pairs_for_fc.at[index_from_pairs, 'Species 1 Score'] = avg_rank_in_species_2\n",
    "\n",
    "    #Repeat for Species 2 \n",
    "\n",
    "    top_10_species_2_genes = np.array(\n",
    "        [double_species_2_trimmed_cococonet.T[c].nlargest(10).index.values for c in double_species_2_trimmed_cococonet.T]\n",
    "    )  # using pair list above, cut down top 10 list to relevant genes, probably by adding list as a column in panda and then filtering panda to index of pair list\n",
    "    top_10_species_2_genes_dataframe = pd.DataFrame(\n",
    "        data=top_10_species_2_genes,\n",
    "        index=double_species_2_trimmed_cococonet.index,\n",
    "        columns=[\n",
    "            \"One\",\n",
    "            \"Two\",\n",
    "            \"Three\",\n",
    "            \"Four\",\n",
    "            \"Five\",\n",
    "            \"Six\",\n",
    "            \"Seven\",\n",
    "            \"Eight\",\n",
    "            \"Nine\",\n",
    "            \"Ten\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "    #convert \n",
    "    top_10_species_2_genes_as_species_1 = top_10_species_2_genes_dataframe\n",
    "\n",
    "\n",
    "    # Get values in species 1 \n",
    "    for two_genes in trimmed_all_gene_pairs_for_fc.iterrows():\n",
    "        current_species_1_gene = two_genes[1][f'{common_name_1} and {common_name_2}']\n",
    "        current_species_2_gene = two_genes[1][f'{common_name_1} and {common_name_2}']\n",
    "        finger_print_genes = top_10_species_2_genes_as_species_1.loc[current_species_2_gene].to_list()\n",
    "        gene_ranks_in_species_1 = species_1_cococonet_ranked.loc[species_1_cococonet_ranked.index.isin(finger_print_genes), current_species_1_gene]\n",
    "        avg_rank_in_species_1 = gene_ranks_in_species_1.mean()\n",
    "        index_from_pairs = two_genes[0]\n",
    "        trimmed_all_gene_pairs_for_fc.loc[index_from_pairs, 'Species 2 Score'] = avg_rank_in_species_1\n",
    "\n",
    "    #Caluclate Divisors \n",
    "    Number_of_species_1_genes = len(top_10_species_1_genes_as_species_2)\n",
    "    Number_of_species_2_genes = len(top_10_species_2_genes_as_species_1)\n",
    "\n",
    "\n",
    "    species_1_score_divisor = Number_of_species_2_genes - 4.5\n",
    "    species_2_score_divisor = Number_of_species_1_genes-4.5\n",
    "\n",
    "    #Divide and Average \n",
    "    trimmed_all_gene_pairs_for_fc['Species 1 Score'] = trimmed_all_gene_pairs_for_fc['Species 1 Score']/species_1_score_divisor\n",
    "    trimmed_all_gene_pairs_for_fc['Species 2 Score'] = trimmed_all_gene_pairs_for_fc['Species 2 Score']/species_2_score_divisor\n",
    "    trimmed_all_gene_pairs_for_fc['Total Score'] = trimmed_all_gene_pairs_for_fc[['Species 1 Score','Species 2 Score']].mean(axis = 1)\n",
    "        \n",
    "    return trimmed_all_gene_pairs_for_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rice_jp and soybean</th>\n",
       "      <th>Species 1 Score</th>\n",
       "      <th>Species 2 Score</th>\n",
       "      <th>Total Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110263at3193</td>\n",
       "      <td>0.711713</td>\n",
       "      <td>0.833536</td>\n",
       "      <td>0.772624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128468at3193</td>\n",
       "      <td>0.896613</td>\n",
       "      <td>0.785427</td>\n",
       "      <td>0.841020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>882547at3193</td>\n",
       "      <td>0.704806</td>\n",
       "      <td>0.792114</td>\n",
       "      <td>0.748460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125951at3193</td>\n",
       "      <td>0.876904</td>\n",
       "      <td>0.829088</td>\n",
       "      <td>0.852996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>678282at3193</td>\n",
       "      <td>0.755169</td>\n",
       "      <td>0.683986</td>\n",
       "      <td>0.719577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6834</th>\n",
       "      <td>683427at3193</td>\n",
       "      <td>0.381125</td>\n",
       "      <td>0.665930</td>\n",
       "      <td>0.523528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6835</th>\n",
       "      <td>878363at3193</td>\n",
       "      <td>0.800907</td>\n",
       "      <td>0.818363</td>\n",
       "      <td>0.809635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6836</th>\n",
       "      <td>123940at3193</td>\n",
       "      <td>0.976619</td>\n",
       "      <td>0.931304</td>\n",
       "      <td>0.953962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6837</th>\n",
       "      <td>875771at3193</td>\n",
       "      <td>0.562719</td>\n",
       "      <td>0.772258</td>\n",
       "      <td>0.667488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6838</th>\n",
       "      <td>718744at3193</td>\n",
       "      <td>0.937537</td>\n",
       "      <td>0.817031</td>\n",
       "      <td>0.877284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6839 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rice_jp and soybean  Species 1 Score  Species 2 Score  Total Score\n",
       "0           110263at3193         0.711713         0.833536     0.772624\n",
       "1           128468at3193         0.896613         0.785427     0.841020\n",
       "2           882547at3193         0.704806         0.792114     0.748460\n",
       "3           125951at3193         0.876904         0.829088     0.852996\n",
       "4           678282at3193         0.755169         0.683986     0.719577\n",
       "...                  ...              ...              ...          ...\n",
       "6834        683427at3193         0.381125         0.665930     0.523528\n",
       "6835        878363at3193         0.800907         0.818363     0.809635\n",
       "6836        123940at3193         0.976619         0.931304     0.953962\n",
       "6837        875771at3193         0.562719         0.772258     0.667488\n",
       "6838        718744at3193         0.937537         0.817031     0.877284\n",
       "\n",
       "[6839 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Calculate_Score_list_for_thresholding(coconet_species_one,coconet_species_two,'rice_jp','soybean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rice_jp and soybean</th>\n",
       "      <th>Species 1 Score</th>\n",
       "      <th>Species 2 Score</th>\n",
       "      <th>Total Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10092at3193</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>0.889823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10147at3193</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>0.873666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10228at3193</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>0.871034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10238at3193</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>0.662195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10525at3193</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>0.656346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6834</th>\n",
       "      <td>9789at3193</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>0.713189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6835</th>\n",
       "      <td>9828at3193</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>0.934566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6836</th>\n",
       "      <td>9877at3193</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>0.955768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6837</th>\n",
       "      <td>9919at3193</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>0.969550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6838</th>\n",
       "      <td>9942at3193</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>compatability col</td>\n",
       "      <td>0.911171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6839 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rice_jp and soybean    Species 1 Score    Species 2 Score  Total Score\n",
       "0            10092at3193  compatability col  compatability col     0.889823\n",
       "1            10147at3193  compatability col  compatability col     0.873666\n",
       "2            10228at3193  compatability col  compatability col     0.871034\n",
       "3            10238at3193  compatability col  compatability col     0.662195\n",
       "4            10525at3193  compatability col  compatability col     0.656346\n",
       "...                  ...                ...                ...          ...\n",
       "6834          9789at3193  compatability col  compatability col     0.713189\n",
       "6835          9828at3193  compatability col  compatability col     0.934566\n",
       "6836          9877at3193  compatability col  compatability col     0.955768\n",
       "6837          9919at3193  compatability col  compatability col     0.969550\n",
       "6838          9942at3193  compatability col  compatability col     0.911171\n",
       "\n",
       "[6839 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sc_table_formatted(coconet_species_one,coconet_species_two,'rice_jp','soybean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_to_run_on = pd.read_csv('/data/passala/Generated_Tables/Reference_tables/species_for_running_cross_ortho_analysis.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_species_to_run_on = species_to_run_on['Common Name'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:04<00:00,  3.13it/s]\n"
     ]
    }
   ],
   "source": [
    "all_coconets = {}\n",
    "for species in tqdm.tqdm(list_of_species_to_run_on):\n",
    "    current_net = pickle.load( open( f\"/data/passala/Generated_Tables/Comparing_all_orthogorups_across_plants/Orthogroups_at_eukaryote_level/Orthogroup_cococonet_eukaryote/{species}_merged_cococonet_pickle.p\", \"rb\" ) )\n",
    "    all_coconets[species] = current_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combos_to_run_on = list(itertools.combinations(list_of_species_to_run_on,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_combos_to_run_on)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_files = os.listdir('/data/passala/Generated_Tables/Comparing_all_orthogorups_across_plants/1_1_ortho_FC_tables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generated_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [1:19:47<00:00, 45.60s/it]\n"
     ]
    }
   ],
   "source": [
    "for combo in tqdm.tqdm(all_combos_to_run_on):\n",
    "    species_1 = combo[0]\n",
    "    species_2 = combo[1]\n",
    "    coconet_spec_1 = all_coconets[species_1]\n",
    "    coconet_spec_2 = all_coconets[species_2]\n",
    "    \n",
    "    score_list = generate_sc_table_formatted(coconet_spec_1, coconet_spec_2, species_1,species_2)\n",
    "    score_list.to_csv(f'/data/passala/Generated_Tables/Comparing_all_orthogorups_across_plants/Orthogroups_at_eukaryote_level/1_1_ortho_SC_tables_eukaryote/{species_1}_{species_2}_NM.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Single_cell_data_fix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
